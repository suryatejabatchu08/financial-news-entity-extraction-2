{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "143e0f28",
   "metadata": {},
   "source": [
    "# Import Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39f7345c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.training.example import Example\n",
    "from spacy.util import minibatch, compounding\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44bf3ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION ---\n",
    "EPOCHS = 30                # Number of training loops\n",
    "BATCH_SIZE = 8             # Process 8 sentences at a time\n",
    "DROPOUT = 0.5              # Randomness to prevent overfitting\n",
    "MODEL_NAME = \"en_core_web_md\" # The base model we are fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd667e41",
   "metadata": {},
   "source": [
    "# 1. LOAD THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa73b53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Loaded 294 training examples.\n"
     ]
    }
   ],
   "source": [
    "# We load the JSON file generated in the training_data.py\n",
    "print(\"Loading dataset...\")\n",
    "try:\n",
    "    with open(\"train_financial_ner.json\", \"r\") as f:\n",
    "        TRAIN_DATA = json.load(f)\n",
    "    print(f\"Loaded {len(TRAIN_DATA)} training examples.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'train_financial_ner.json' not found. Please run the Data Generation script first!\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9912476",
   "metadata": {},
   "source": [
    "# 2. LOAD THE BASE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a41de807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the medium English model (must install first: python -m spacy download en_core_web_md)\n",
    "nlp = spacy.load(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640228e2",
   "metadata": {},
   "source": [
    "# 3. SETUP THE PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18f54836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if NER pipe exists, if not add it\n",
    "if \"ner\" not in nlp.pipe_names:\n",
    "    ner = nlp.add_pipe(\"ner\")\n",
    "else:\n",
    "    ner = nlp.get_pipe(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11960976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding labels to model...\n"
     ]
    }
   ],
   "source": [
    "# 4. ADD NEW LABELS\n",
    "# The video loops through data to find labels. We do the same.\n",
    "print(\"Adding labels to model...\")\n",
    "for _, annotations in TRAIN_DATA:\n",
    "    for ent in annotations.get(\"entities\"):\n",
    "        ner.add_label(ent[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf170c21",
   "metadata": {},
   "source": [
    "# 5. DISABLE OTHER PIPELINES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c22beb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only want to train NER, not the tagger or parser\n",
    "pipe_exceptions = [\"ner\", \"trf_tok2vec\", \"tok2vec\"]\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49accf05",
   "metadata": {},
   "source": [
    "# 6. TRAINING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a00df30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 30 epochs...\n",
      "Epoch 1/30 - Loss: 1009.74\n",
      "Epoch 2/30 - Loss: 705.48\n",
      "Epoch 3/30 - Loss: 616.31\n",
      "Epoch 4/30 - Loss: 544.89\n",
      "Epoch 5/30 - Loss: 502.09\n",
      "Epoch 6/30 - Loss: 479.55\n",
      "Epoch 7/30 - Loss: 448.28\n",
      "Epoch 8/30 - Loss: 419.45\n",
      "Epoch 9/30 - Loss: 415.54\n",
      "Epoch 10/30 - Loss: 418.23\n",
      "Epoch 11/30 - Loss: 392.82\n",
      "Epoch 12/30 - Loss: 371.98\n",
      "Epoch 13/30 - Loss: 408.09\n",
      "Epoch 14/30 - Loss: 343.58\n",
      "Epoch 15/30 - Loss: 321.66\n",
      "Epoch 16/30 - Loss: 323.94\n",
      "Epoch 17/30 - Loss: 286.59\n",
      "Epoch 18/30 - Loss: 271.66\n",
      "Epoch 19/30 - Loss: 286.69\n",
      "Epoch 20/30 - Loss: 264.65\n",
      "Epoch 21/30 - Loss: 283.77\n",
      "Epoch 22/30 - Loss: 264.30\n",
      "Epoch 23/30 - Loss: 234.17\n",
      "Epoch 24/30 - Loss: 258.32\n",
      "Epoch 25/30 - Loss: 244.17\n",
      "Epoch 26/30 - Loss: 215.37\n",
      "Epoch 27/30 - Loss: 201.50\n",
      "Epoch 28/30 - Loss: 199.02\n",
      "Epoch 29/30 - Loss: 198.20\n",
      "Epoch 30/30 - Loss: 220.11\n"
     ]
    }
   ],
   "source": [
    "print(f\"Starting training for {EPOCHS} epochs...\")\n",
    "with nlp.disable_pipes(*other_pipes):\n",
    "    \n",
    "    # Initialize optimizer\n",
    "    optimizer = nlp.create_optimizer()\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "        \n",
    "        # Create batches\n",
    "        # We use compounding to start with small batches and increase them\n",
    "        batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
    "        \n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            \n",
    "            # Convert to spaCy 'Example' objects (Required for spaCy v3)\n",
    "            examples = []\n",
    "            for i in range(len(texts)):\n",
    "                doc = nlp.make_doc(texts[i])\n",
    "                example = Example.from_dict(doc, annotations[i])\n",
    "                examples.append(example)\n",
    "            \n",
    "            # Update the model\n",
    "            nlp.update(\n",
    "                examples,\n",
    "                drop=DROPOUT,\n",
    "                losses=losses,\n",
    "                sgd=optimizer\n",
    "            )\n",
    "            \n",
    "        print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {losses['ner']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a48d78",
   "metadata": {},
   "source": [
    "# 7. SAVE THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc75a52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model saved to directory: financial_ner_model\n"
     ]
    }
   ],
   "source": [
    "output_dir = \"financial_ner_model\"\n",
    "nlp.to_disk(output_dir)\n",
    "print(f\"\\nModel saved to directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99853076",
   "metadata": {},
   "source": [
    "# 8. TEST THE MODEL (Immediate Sanity Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "193bbedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TESTING THE NEW MODEL ---\n",
      "\n",
      "Text: Apple (AAPL) announced the acquisition of an AI startup for $50 million.\n",
      "  Apple -> ORG\n",
      "  AAPL -> TICKER\n",
      "  acquisition -> EVENT\n",
      "  $50 million -> MONEY\n",
      "\n",
      "Text: The CPI rose 0.4% in March, signaling inflation.\n",
      "  0.4% -> PERCENT\n",
      "  March -> DATE\n",
      "\n",
      "Text: Nvidia announced a stock split after hitting $900.\n",
      "  Nvidia -> ORG\n",
      "  stock split -> EVENT\n",
      "  $900 -> MONEY\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- TESTING THE NEW MODEL ---\")\n",
    "test_sentences = [\n",
    "    \"Apple (AAPL) announced the acquisition of an AI startup for $50 million.\",\n",
    "    \"The CPI rose 0.4% in March, signaling inflation.\",\n",
    "    \"Nvidia announced a stock split after hitting $900.\"\n",
    "]\n",
    "\n",
    "for text in test_sentences:\n",
    "    doc = nlp(text)\n",
    "    print(f\"\\nText: {text}\")\n",
    "    for ent in doc.ents:\n",
    "        print(f\"  {ent.text} -> {ent.label_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa216e2",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5efe7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: financial_ner_model...\n",
      "Loading validation data from: dev_financial_ner.json...\n",
      "Evaluating on 66 examples...\n",
      "\n",
      "========================================\n",
      "METRIC          | SCORE     \n",
      "========================================\n",
      "Precision       | 77.40%\n",
      "Recall          | 82.56%\n",
      "F1-Score        | 79.90%\n",
      "========================================\n",
      "\n",
      "Breakdown by Entity Type:\n",
      "ENTITY       | PRECISION  | RECALL     | F1        \n",
      "------------------------------------------------\n",
      "DATE         | 90.00%    | 100.00%    | 94.74%\n",
      "EVENT        | 57.14%    | 44.44%    | 50.00%\n",
      "INDICATOR    | 10.00%    | 20.00%    | 13.33%\n",
      "MONEY        | 85.71%    | 96.00%    | 90.57%\n",
      "ORG          | 78.49%    | 85.88%    | 82.02%\n",
      "PER          | 71.43%    | 90.91%    | 80.00%\n",
      "PERCENT      | 93.75%    | 93.75%    | 93.75%\n",
      "ROLE         | 85.71%    | 100.00%    | 92.31%\n",
      "TICKER       | 76.92%    | 50.00%    | 60.61%\n"
     ]
    }
   ],
   "source": [
    "!python evaluate_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f1baa5",
   "metadata": {},
   "source": [
    "# Update Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9973ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 294 existing examples.\n",
      "Success! Added 30 new repair examples.\n",
      "Total Training Dataset Size: 324\n"
     ]
    }
   ],
   "source": [
    "!python update_dataset.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302919c9",
   "metadata": {},
   "source": [
    "# Evaluate model after updating Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "901fe6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: financial_ner_model...\n",
      "Loading validation data from: dev_financial_ner.json...\n",
      "Evaluating on 66 examples...\n",
      "\n",
      "========================================\n",
      "METRIC          | SCORE     \n",
      "========================================\n",
      "Precision       | 77.40%\n",
      "Recall          | 82.56%\n",
      "F1-Score        | 79.90%\n",
      "========================================\n",
      "\n",
      "Breakdown by Entity Type:\n",
      "ENTITY       | PRECISION  | RECALL     | F1        \n",
      "------------------------------------------------\n",
      "DATE         | 90.00%    | 100.00%    | 94.74%\n",
      "EVENT        | 57.14%    | 44.44%    | 50.00%\n",
      "INDICATOR    | 10.00%    | 20.00%    | 13.33%\n",
      "MONEY        | 85.71%    | 96.00%    | 90.57%\n",
      "ORG          | 78.49%    | 85.88%    | 82.02%\n",
      "PER          | 71.43%    | 90.91%    | 80.00%\n",
      "PERCENT      | 93.75%    | 93.75%    | 93.75%\n",
      "ROLE         | 85.71%    | 100.00%    | 92.31%\n",
      "TICKER       | 76.92%    | 50.00%    | 60.61%\n"
     ]
    }
   ],
   "source": [
    "!python evaluate_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afb6f94",
   "metadata": {},
   "source": [
    "# Update Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdd06d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 66 existing Dev examples.\n",
      "Success! Added 15 new examples to the Dev Set.\n",
      "New Dev Set Size: 81\n"
     ]
    }
   ],
   "source": [
    "!python update_dev.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87a6a50",
   "metadata": {},
   "source": [
    "# Evaluate on updated Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb682813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: financial_ner_model...\n",
      "Loading validation data from: dev_financial_ner.json...\n",
      "Evaluating on 81 examples...\n",
      "\n",
      "========================================\n",
      "METRIC          | SCORE     \n",
      "========================================\n",
      "Precision       | 75.31%\n",
      "Recall          | 82.19%\n",
      "F1-Score        | 78.60%\n",
      "========================================\n",
      "\n",
      "Breakdown by Entity Type:\n",
      "ENTITY       | PRECISION  | RECALL     | F1        \n",
      "------------------------------------------------\n",
      "DATE         | 85.71%    | 100.00%    | 92.31%\n",
      "EVENT        | 71.43%    | 58.82%    | 64.52%\n",
      "INDICATOR    | 31.25%    | 41.67%    | 35.71%\n",
      "MONEY        | 77.42%    | 96.00%    | 85.71%\n",
      "ORG          | 79.61%    | 87.23%    | 83.25%\n",
      "PER          | 71.43%    | 90.91%    | 80.00%\n",
      "PERCENT      | 75.00%    | 93.75%    | 83.33%\n",
      "ROLE         | 85.71%    | 100.00%    | 92.31%\n",
      "TICKER       | 76.92%    | 50.00%    | 60.61%\n"
     ]
    }
   ],
   "source": [
    "!python evaluate_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af647ce",
   "metadata": {},
   "source": [
    "# Model is Ready to use on real text!! ðŸŽ‰ðŸ—¿"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
